# 机器学习教程


<!--more-->

## 机器学习简介

机器学习的对象是数据。从数据出发，提取数据特征，发现数据中的知识，然后又回到对数据的分析预测中去。因此，在机器学习的假设中有很重要的一个假设，那就是假设同类数据的数据有一定的统计特性。这样机器学习通过考虑学习什么样的模型以及如何学习的问题，使得模型能读数据进行准确的预测与分析。

### 机器学习的组成

- **监督学习（Supervised Learning）**
  1. 可以由训练集（Training Set）中学到或建立一个模式，并依此模式推测新的实例。训练集是由输入（通常是矩阵）和预期输出所组成。函数的输出可以是一个连续的值（回归，Regression），或是一个离散的类别标签（分类，Classification）。
  1. 一个监督学习的任务在观察完一些训练范例（输入和预期输出）后，去预测这个函数对任何可能出现的输入的值的输出。要达到此目的，学习者必须以"合理"（见归纳偏向）的方式从现有的资料中一般化到非观察到的情况。在人类和动物感知中，则通常被称为概念学习（Concept Learning）。
  1. 监督学习有两种形态的模型。最一般的，监督式学习产生一个全域模型，会将输入对应到预期输出。而另一种，则是将这种对应实作在一个区域模型。（如案例推论及最近邻居法）。
  1. 常用分类器：人工神经网络（ANN）、支持向量机（SVM）、K-近邻算法（KNN）、高斯混合模型（GMM）、朴素贝叶斯分类器（NBC）、决策树（DT）和径向基函数（RBF）。
- **无监督学习（Unsupervised Learning）**
  1. 目的是去对原始资料进行分类，以便了解资料内部结构。有别于监督式学习网络，无监督式学习网络在学习时并不知道其分类结果是否正确，亦即没有受到监督式增强(告诉它何种学习是正确的)。其特点是仅对此种网络提供输入范例，而它会自动从这些范例中找出其潜在类别规则。当学习完毕并经测试后，也可以将之应用到新的案例上。
  1. 无监督学习里典型的例子就是聚类了。聚类的目的在于把相似的东西聚在一起，而我们并不关心这一类是什么。因此，一个聚类算法通常只需要知道如何计算相似度就可以开始工作了。
- **半监督学习（Semi-supervised Learning）**
  1. 给定一个来自某未知分布的样本集S=L∪U, 其中L 是已标签样本集L={(x1,y1),(x2,y2), … ,(x |L|,y|L|)}, U是一个未标签样本集U={x’1,x’2,…,x’|U|},希望得到函数f:X → Y可以准确地对样本x预测其标签y，这个函数可能是参数的，如最大似然法；可能是非参数的，如最邻近法、神经网络法、支持向量机法等；也可能是非数值的，如决策树分类。其中, x与x’  均为d 维向量, yi∈Y 为样本x i 的标签, |L| 和|U| 分别为L 和U 的大小, 即所包含的样本数。半监督学习就是在样本集S 上寻找最优的学习器。如何综合利用已标签样例和未标签样例,是半监督学习需要解决的问题。
  1. 半监督学习问题从样本的角度而言是利用少量标注样本和大量未标注样本进行机器学习，从概率学习角度可理解为研究如何利用训练样本的输入边缘概率 P( x )和条件输出概率P ( y | x )的联系设计具有良好性能的分类器。这种联系的存在是建立在某些假设的基础上的，即聚类假设(cluster  assumption)和流形假设(maniford assumption)。
- **强化学习（Reinforcement Learning）**
  1. 强化学习是从动物学习、参数扰动自适应控制等理论发展而来，其基本原理是：如果Agent的某个行为策略导致环境正的奖赏(强化信号)，那么Agent以后产生这个行为策略的趋势便会加强。Agent的目标是在每个离散状态发现最优策略以使期望的折扣奖赏和最大。
  1. 强化学习把学习看作试探评价过程，Agent选择一个动作用于环境，环境接受该动作后状态发生变化，同时产生一个强化信号(奖或惩)反馈给Agent，Agent根据强化信号和环境当前状态再选择下一个动作，选择的原则是使受到正强化(奖)的概率增大。选择的动作不仅影响立即强化值，而且影响环境下一时刻的状态及最终的强化值。
  1. 强化学习不同于连接主义学习中的监督学习，主要表现在教师信号上，强化学习中由环境提供的强化信号是Agent对所产生动作的好坏作一种评价(通常为标量信号)，而不是告诉Agent如何去产生正确的动作。由于外部环境提供了很少的信息，Agent必须靠自身的经历进行学习。通过这种方式，Agent在行动一一评价的环境中获得知识，改进行动方案以适应环境。
  1. 强化学习系统学习的目标是动态地调整参数，以达到强化信号最大。若已知r/A梯度信息，则可直接可以使用监督学习算法。因为强化信号r与Agent产生的动作A没有明确的函数形式描述，所以梯度信息r/A无法得到。因此，在强化学习系统中，需要某种随机单元，使用这种随机单元，Agent在可能动作空间中进行搜索并发现正确的动作。

### 过拟合与欠拟合

机器学习的主要挑战任务是我们的模型能够在先前未观测的新输入上表现良好，而不是仅仅在训练数据集上效果良好。这儿，将在先前未观测输入上的表现能力称之为泛化（generalization）。

通过训练数据集训练模型后在训练数据上进行的一些误差计算称之为训练误差（training error）

在进行机器学习建模时我们不仅希望我们的训练误差很小，同时我们的最终目的是使得测试误差（test error）很小，也就是泛化误差（Generalization error）很小。

$$ \frac{1}{m^{(train)}}||X^{(train)}w-y^{(train)}||_2^2 $$

$$ \frac{1}{m^{(test)}}||X^{(test)}w-y^{(test)}||_2^2 $$

### 评价指标

## 线性回归

### 范数正则与Lasso详解

## 最大似然估计

## 线性判别式分析

## 决策树

### ID3

### C4.5

## 朴素贝叶斯

## 感知机

## 最大熵模型

## 支持向量机

### 支持向量回归机

## 神经网络

### 前向传播

### 反向传播

### 激活函数

### 损失函数

## 集成学习

### boosting 与 bagging

### 随机森林

## 聚类

### K-Means


